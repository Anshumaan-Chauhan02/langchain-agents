{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4df8349f",
   "metadata": {},
   "source": [
    "## Agent Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94d9ca57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def add(x: float, y: float) -> float:\n",
    "    \"\"\"Add 'x' and 'y'.\"\"\"\n",
    "    return x+y\n",
    "\n",
    "@tool\n",
    "def multiply(x: float, y: float) -> float:\n",
    "    \"\"\"Multiply 'x' and 'y'.\"\"\"\n",
    "    return x*y\n",
    "\n",
    "@tool\n",
    "def exponentiate(x: float, y: float) -> float:\n",
    "    \"\"\"Exponentiate 'x' to the power of 'y'.\"\"\"\n",
    "    return x**y\n",
    "\n",
    "@tool\n",
    "def subtract(x: float, y: float) -> float:\n",
    "    \"\"\"Subtract 'x' from 'y'.\"\"\"\n",
    "    return y-x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ff53fa",
   "metadata": {},
   "source": [
    "With the @tool decorator our function is turned into a StructuredTool object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2cab5b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredTool(name='add', description=\"Add 'x' and 'y'.\", args_schema=<class 'langchain_core.utils.pydantic.add'>, func=<function add at 0x7f7eae2ce020>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5994d089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add\n",
      "Add 'x' and 'y'.\n"
     ]
    }
   ],
   "source": [
    "print(f\"{add.name}\\n{add.description}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e2474c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': \"Add 'x' and 'y'.\",\n",
       " 'properties': {'x': {'title': 'X', 'type': 'number'},\n",
       "  'y': {'title': 'Y', 'type': 'number'}},\n",
       " 'required': ['x', 'y'],\n",
       " 'title': 'add',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add.args_schema.model_json_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83b9f2b",
   "metadata": {},
   "source": [
    "When invoking the tool, a JSON string output by the LLM will be parsed into JSON and then consumed as kwargs, similar to below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01d33f7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': 5, 'y': 2}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json \n",
    "\n",
    "llm_output_string = \"{\\\"x\\\":5, \\\"y\\\":2}\"\n",
    "llm_output_dict = json.loads(llm_output_string)\n",
    "llm_output_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf74056",
   "metadata": {},
   "source": [
    "This is then passed into the tool function as kwargs (keyword arguments) as indicated by the ** operator - the ** operator is used to unpack the dictionary into keyword arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b056898c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exponentiate.func(**llm_output_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce76e45c",
   "metadata": {},
   "source": [
    "## Creating an Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0d4e185",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant\"),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"placeholder\", \"{agent_scratchpad}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f4f1525",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"qwen3:0.6b\", temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "095f0918",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_124913/4074810399.py:3: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676fa614",
   "metadata": {},
   "source": [
    "Now we can initialize our agent that needs \n",
    "\n",
    "1. llm\n",
    "2. tools\n",
    "3. prompt\n",
    "4. memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b591ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_tool_calling_agent\n",
    "tools = [add, subtract, exponentiate, multiply]\n",
    "agent = create_tool_calling_agent(\n",
    "    llm=llm, tools=tools, prompt=prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd42d646",
   "metadata": {},
   "source": [
    "Our agent by itself is like on-step of our agent execution loop. So, if we call agent.invoke method it will get the LLM to geenrate a single response and go no further, so no tools will be executed, and no next iterations will be performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ff53c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ToolAgentAction(tool='multiply', tool_input={'x': 10.7, 'y': 7.68}, log=\"\\nInvoking: `multiply` with `{'x': 10.7, 'y': 7.68}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'qwen3:0.6b', 'created_at': '2025-05-18T21:39:56.879918955Z', 'done': True, 'done_reason': 'stop', 'total_duration': 3130729732, 'load_duration': 2319377267, 'prompt_eval_count': 355, 'prompt_eval_duration': 364436420, 'eval_count': 108, 'eval_duration': 435173587, 'model_name': 'qwen3:0.6b'}, id='run--eb729e63-35cf-425e-88c5-59d1f05d1e36-0', tool_calls=[{'name': 'multiply', 'args': {'x': 10.7, 'y': 7.68}, 'id': 'b02a1db7-b17b-4e4d-80d3-fd896f2dd701', 'type': 'tool_call'}], usage_metadata={'input_tokens': 355, 'output_tokens': 108, 'total_tokens': 463})], tool_call_id='b02a1db7-b17b-4e4d-80d3-fd896f2dd701')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke({\n",
    "    \"input\": \"What is 10.7 multiplied by 7.68?\",\n",
    "    \"chat_history\": memory.chat_memory.messages,\n",
    "    \"intermediate_steps\": [] # agent appends its steps here\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96f6523",
   "metadata": {},
   "source": [
    "We know LLM wants to use a tool and has parameters for it. But we do not have the answer, the reason is LLM cannot execute the function -> we need agent executor for it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abec44a8",
   "metadata": {},
   "source": [
    "## Agent Executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "695d94e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    memeory=memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59bc2c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `multiply` with `{'x': 10.7, 'y': 7.68}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m82.17599999999999\u001b[0m\u001b[32;1m\u001b[1;3m<think>\n",
      "Okay, the user asked, \"What is 10.7 multiplied by 7.68?\" I need to use the multiply function. Let me check the tools provided. Yes, there's a multiply function that takes two numbers. So I'll call multiply with x=10.7 and y=7.68. Then, the response should be the product, which is approximately 82.18. I should present that clearly.\n",
      "</think>\n",
      "\n",
      "The result of multiplying 10.7 by 7.68 is approximately 82.18.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is 10.7 multiplied by 7.68?',\n",
       " 'chat_history': [],\n",
       " 'output': '<think>\\nOkay, the user asked, \"What is 10.7 multiplied by 7.68?\" I need to use the multiply function. Let me check the tools provided. Yes, there\\'s a multiply function that takes two numbers. So I\\'ll call multiply with x=10.7 and y=7.68. Then, the response should be the product, which is approximately 82.18. I should present that clearly.\\n</think>\\n\\nThe result of multiplying 10.7 by 7.68 is approximately 82.18.'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\n",
    "    \"input\": \"What is 10.7 multiplied by 7.68?\",\n",
    "    \"chat_history\": memory.chat_memory.messages,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6cf2ef64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `multiply` with `{'x': 10.7, 'y': 7.68}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m82.17599999999999\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `subtract` with `{'x': 82.176, 'y': 20.18}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m-61.996\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `add` with `{'x': 62, 'y': 30}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m92.0\u001b[0m\u001b[32;1m\u001b[1;3m<think>\n",
      "Okay, let's see. The user asked for the result of 10.7 multiplied by 7.68, subtracted by 20.18, and added by 30. I need to calculate each step and then combine them.\n",
      "\n",
      "First, multiply 10.7 and 7.68. Let me do that. 10.7 times 7.68. Let me compute that. 10 times 7.68 is 76.8, and 0.7 times 7.68 is 5.376. Adding those gives 82.176. So the first part is 82.176.\n",
      "\n",
      "Next, subtract 20.18 from that result. So 82.176 minus 20.18. Let me subtract. 82.176 - 20 is 62.176, then subtract 0.18 more, which gives 62.0. So that's -61.996.\n",
      "\n",
      "Then, add 30 to the result. 62.0 plus 30 is 92.0. So the final result is 92.0.\n",
      "\n",
      "Wait, but the user might want the exact decimal places. Let me check the original numbers. The original numbers are given as 10.7, 7.68, 20.18, and 30. All are precise to two decimal places except maybe the 10.7 which is one decimal place. But when multiplying, the precision is determined by the least precise measurement. However, in most cases, these numbers are considered exact for the purpose of calculation. So the final answer should be 92.0, which is exact.\n",
      "\n",
      "I think that's it. The steps are correct, and the final result is 92.0.\n",
      "</think>\n",
      "\n",
      "The final result is 92.0.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is 10.7 multiplied by 7.68, subtracted by 20.18, and added by 30?',\n",
       " 'chat_history': [],\n",
       " 'output': \"<think>\\nOkay, let's see. The user asked for the result of 10.7 multiplied by 7.68, subtracted by 20.18, and added by 30. I need to calculate each step and then combine them.\\n\\nFirst, multiply 10.7 and 7.68. Let me do that. 10.7 times 7.68. Let me compute that. 10 times 7.68 is 76.8, and 0.7 times 7.68 is 5.376. Adding those gives 82.176. So the first part is 82.176.\\n\\nNext, subtract 20.18 from that result. So 82.176 minus 20.18. Let me subtract. 82.176 - 20 is 62.176, then subtract 0.18 more, which gives 62.0. So that's -61.996.\\n\\nThen, add 30 to the result. 62.0 plus 30 is 92.0. So the final result is 92.0.\\n\\nWait, but the user might want the exact decimal places. Let me check the original numbers. The original numbers are given as 10.7, 7.68, 20.18, and 30. All are precise to two decimal places except maybe the 10.7 which is one decimal place. But when multiplying, the precision is determined by the least precise measurement. However, in most cases, these numbers are considered exact for the purpose of calculation. So the final answer should be 92.0, which is exact.\\n\\nI think that's it. The steps are correct, and the final result is 92.0.\\n</think>\\n\\nThe final result is 92.0.\"}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\n",
    "    \"input\": \"What is 10.7 multiplied by 7.68, subtracted by 20.18, and added by 30?\",\n",
    "    \"chat_history\": memory.chat_memory.messages,\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
