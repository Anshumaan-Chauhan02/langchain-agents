# LangChain

LangCHain is a powerful Python library for agentic systems. It allows us to do a lot of abstraction in the code and helps us to create agents easily. LangChain ecosystem folllows a similar pattern so the concepts learnt here can be applied to LangGraph, LangSmith, etc. Moreover, we can later on customizer the code and remocve the abstraction to make our code more customized for our own needs. 

We will be using `ollama` package for accessing LLMs. 

Let's setup the project and install all the dependencies using `uv`. 
1. `uv init langchain-agents`
2. `uv venv --python 3.12.7`
   1. To check list of all python version installed on your system run `uv python list`
3. Activate the virtual env -> `source .venv/bin/activate`
4. `uv add langchain-core langchain-ollama langsmith docarray langchain-community ipykernel langchain fastapi uvicorn google-search-results ollama`
5. Prerequisites for using ollama python library is that it should be installed on your system. For more information check [installation guide](https://github.com/ollama/ollama-python).
   1. If working on WSL, install ollama on your system using
   ```
   curl -fsSL https://ollama.com/install.sh | sh
   ```
6. Pull Qwen model -> `ollama pull qwen3:0.6b`
7. To confirm everything is working fine run `uv run ollama_basics.py`

You can check more details such as options to edit model settings in [Ollama REST API](https://github.com/ollama/ollama/blob/main/docs/api.md).

![](docs/imgs/ollama_model_options.png)


### Quick Fixes if opening VS Code in WSL
1. Try selecting the correct intrerpreter for Pylance to access libraries, etc. 
   1. Select Interpreter (either from bottom right of the screen or by choosing it by `Ctrl + Shift + P`) -> Enter Interpreter Path -> `.venv/bin/python` , can choose `python3` or `python3.12`.  
2. Try reloading the Window -> `Ctrl + Shift + P` -> `Reload Window` 


THroughout we are using a mix of DeepSeek-R1 and Qwen3 models -> non instruction tuned versions, that is why we are observing such wierd responses. It is better to use instruction tuned models for example Llama3 to get better experience.

# LangChain Ecosystem
### LangChain Core
Foundational fframework that provides abstractions for building LLM-driven applications.

### LangSmith


### LangGraph

### LangServe

### LangFlow

## LangChain Prompt Basics 
There are essentially 3 types of prompts:
1. System Prompts - THey provide LLM information about what its objective is and how should it go about to solve that objective.  
2. User Prompts - It usually contains the context and the problem statement that the user wants LLM to solve
3. AI Prompts - It is the response generated by the LLM for the user prompt

LangChain has several templates for each one of them.

## LangSmith
LangSmith is part of the LangChain ecoystem and is used to track/see how your LLMs and agents are doing. It focuses on debugigng, testing, evaluating and monitoring LLM applications.

Using LangSmith needs an API key, however there is a freee tier version available, which will be sufficient for now.

## Prompting
Usually prompts will consist of:
1. Rule for our LLM -> How the LLM should behave and some instructions on objectives, etc. We need to provide good amount of context, but do not overdo it
2. Context - External information we are feeding into LLM that will help the LLM to solve the objective (It is also called Retireval Augmented Information) - as we are providing external info to LLM. User/Assistant/Tool
3. Question - Task that you want it to solve. User 
4. Answer - This is the output we get from LLM

## Chat Memory
Coversational Memory allows LLMs to remmeber previous information, otherwise LLMs just responsd to the latest message, and that is not conversational. 
- ConversationBufferMemory => Store all messages in a list 
- ConversationBufferWindowMemory => Does not reatin all messages, retains messages within the window size specified 
- ConversationSummaryMemory => Summarize interactions and store it
- ConversationSummaryBufferMemory => List of recent messages (a limit on tokens) + Summary




