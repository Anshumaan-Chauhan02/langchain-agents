{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42cf5b91",
   "metadata": {},
   "source": [
    "## LCEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b58e6b",
   "metadata": {},
   "source": [
    "### Traditional LLMCHain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f0599e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "prompt_template = \"Give me a small report on {topic}\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=['topic'],\n",
    "    template=prompt_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13e71fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"qwen3:0.6b\", temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2169e661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\nOkay, the user said \"Hello there.\" I need to respond appropriately. Let me start by acknowledging their greeting. A simple \"Hello there!\" is a good start. Then, I should offer assistance. Maybe ask how I can help them. It\\'s important to be friendly and open-ended. Let me make sure the response is natural and conversational. I should avoid any technical terms and keep the tone friendly. Alright, putting it all together.\\n</think>\\n\\nHello there! How can I assist you today? ðŸ˜Š', additional_kwargs={}, response_metadata={'model': 'qwen3:0.6b', 'created_at': '2025-05-18T21:56:07.536755542Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2337117464, 'load_duration': 1736354519, 'prompt_eval_count': 10, 'prompt_eval_duration': 221821656, 'eval_count': 107, 'eval_duration': 378112410, 'model_name': 'qwen3:0.6b'}, id='run--2289ed1c-c0fa-4e47-9a66-5ba87aa8263f-0', usage_metadata={'input_tokens': 10, 'output_tokens': 107, 'total_tokens': 117})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Hello there\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af613c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.output_parser import StrOutputParser\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d0796aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_139388/841205956.py:3: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain = LLMChain(\n",
    "    prompt=prompt,\n",
    "    llm=llm,\n",
    "    output_parser=output_parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cd773b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'AI',\n",
       " 'text': '<think>\\nOkay, the user wants a small report on AI. Let me start by understanding the context. They might be a student, a researcher, or someone interested in AI. Since it\\'s a small report, I should keep it concise but informative.\\n\\nFirst, I need to outline the main points. Maybe start with an introduction explaining what AI is and its importance. Then, discuss the key areas: machine learning, natural language processing, computer vision, and robotics. Each section should have a brief explanation and maybe a brief example. Including some statistics or recent developments would add value. Finally, a conclusion to summarize the main points.\\n\\nWait, the user mentioned \"small report,\" so I should avoid too much detail. Make sure each section is concise. Also, check for any technical terms and explain them if necessary. Ensure the report flows well and is easy to read. Let me structure it step by step to cover all necessary aspects without overwhelming the reader.\\n</think>\\n\\n**AI Report: A Small Overview**\\n\\n**Introduction**  \\nArtificial Intelligence (AI) is a technological field that enables machines to perform tasks typically required by humans. It encompasses machine learning, natural language processing, computer vision, and robotics, among other applications. AI drives innovations in healthcare, finance, education, and more, making it a vital field of study and application.\\n\\n**Key Areas**  \\n1. **Machine Learning**  \\n   AI relies on algorithms that learn from data. For example, a spam filter learns to identify patterns in emails to classify them as spam. This process involves training models on large datasets and improving accuracy over time.\\n\\n2. **Natural Language Processing (NLP)**  \\n   AI enables machines to understand and generate human language. Tools like chatbots and language translation services use NLP to interact with users, improving efficiency and accessibility.\\n\\n3. **Computer Vision**  \\n   AI processes images and videos to perform tasks like object recognition or facial detection. Applications include self-driving cars and facial recognition systems, which rely on AI to analyze visual data.\\n\\n4. **Robotics**  \\n   AI-powered robots perform tasks autonomously, such as manufacturing or delivery. This field has applications in industries like healthcare and logistics.\\n\\n**Recent Developments**  \\n- AI has become more integrated into everyday life, from self-driving cars to personalized recommendations on social media.\\n- Advances in quantum computing and neuromorphic engineering are pushing AI to new limits in processing power and efficiency.\\n\\n**Conclusion**  \\nAI is a transformative field with vast potential. While it offers significant benefits, challenges such as data privacy and ethical concerns remain. As AI continues to evolve, its impact on society will shape the future of technology.\\n\\n**End of Report**'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"AI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f149fb2",
   "metadata": {},
   "source": [
    "This is quite restrictive and has a lot of requirements to be pre initialized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d1b644",
   "metadata": {},
   "source": [
    "### LCEL Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dff6ffa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lcel_chain = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ade3331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\nOkay, the user wants a small report on RAG. Let me start by understanding what RAG is. RAG stands for Retrieval-Augmented Generation, which is a technique used in AI to improve the performance of large language models. It combines the strengths of both retrieval and generation models.\\n\\nFirst, I need to outline the main components of RAG. Retrieval is about finding relevant information, and generation is about creating new text. So, the report should explain both parts. Maybe start with the basics, like how RAG works. Then, discuss the benefits, such as improved accuracy and efficiency. \\n\\nI should also mention the applications, like in research papers, news articles, or customer service. That shows real-world use. Including some examples would make it more concrete. Maybe mention specific industries where RAG is applied, like healthcare or finance. \\n\\nWait, the user said \"small report,\" so it should be concise. Avoid too much technical jargon. Make sure to highlight the key points without getting too detailed. Also, check if there are any recent developments or updates in RAG that I should include. But since it\\'s a small report, maybe stick to the standard components. \\n\\nI need to structure the report logically. Start with an introduction, then the components, benefits, applications, and a conclusion. Keep each section brief. Let me verify if I\\'m missing anything. Oh, maybe include a section on how RAG improves performance compared to traditional models. That\\'s a good point. Also, mention the trade-offs, like increased computational cost, but that\\'s a minor point. \\n\\nFinally, ensure the language is clear and the report is easy to read. Make sure there are no markdown elements and the content is in English. Alright, that should cover it.\\n</think>\\n\\n**Report on Retrieval-Augmented Generation (RAG)**  \\n\\n**Introduction**  \\nRAG is a technique that enhances the performance of large language models (LLMs) by combining retrieval and generation processes. It improves accuracy and efficiency by first retrieving relevant information from a database, then generating new text based on that retrieval.  \\n\\n**Key Components**  \\n1. **Retrieval**:  \\n   - Identifies relevant documents or data from a large corpus.  \\n   - Ensures the model focuses on high-quality, relevant information.  \\n\\n2. **Generation**:  \\n   - Uses the retrieved data to generate new, contextually relevant text.  \\n\\n**Benefits**  \\n- **Improved Accuracy**: RAG reduces bias and enhances the modelâ€™s ability to generate high-quality, contextually appropriate responses.  \\n- **Efficiency**: Reduces the need for extensive training data, making models faster and more scalable.  \\n- **Scalability**: Supports large-scale deployment by leveraging pre-existing knowledge bases.  \\n\\n**Applications**  \\n- **Research Papers**: Enhances article writing by ensuring content is factually accurate.  \\n- **News Articles**: Improves the quality of news generation by incorporating verified information.  \\n- **Customer Service**: Provides faster, contextually relevant responses to customer inquiries.  \\n\\n**Conclusion**  \\nRAG optimizes LLM performance by balancing retrieval and generation, making it a powerful tool for real-world applications. While it increases computational costs, its benefits in accuracy and efficiency make it a valuable addition to modern AI systems.  \\n\\n---  \\n*End of Report*'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lcel_chain.invoke(\"RAG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b609eb57",
   "metadata": {},
   "source": [
    "How does LCEL work?\n",
    "\n",
    "The concept is reasonably simple, you start on the far left side of the line, look at the first variable, and the output to that variable is passed into the next variable, before we had prompt | llm | output_parser, we can see that the prompt, feeds into the model, then the model result feeds into the output parser.\n",
    "\n",
    "When we use the pipe operator | we are basically looking for a or function, this is where we can find a chained functionallity to the variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2981fa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Runnable:\n",
    "    def __init__(self, func):\n",
    "        self.func = func\n",
    "    def __or__(self, other):\n",
    "        def chained_func(*args, **kwargs):\n",
    "            # Run the other function with its inputs as the output of the Runnable function\n",
    "            return other(self.func(*args, **kwargs))\n",
    "        return Runnable(chained_func)\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.func(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cf76ae",
   "metadata": {},
   "source": [
    "To create such Runnable class in LangChain, we use RunnableLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23abe669",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "def add_five(x):\n",
    "    return x+5\n",
    "def sub_five(x):\n",
    "    return x-5\n",
    "def mul_five(x):\n",
    "    return x*5\n",
    "\n",
    "add_five = RunnableLambda(add_five)\n",
    "sub_five = RunnableLambda(sub_five)\n",
    "mul_five = RunnableLambda(mul_five)\n",
    "\n",
    "chain = add_five | sub_five | mul_five"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7370716d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
